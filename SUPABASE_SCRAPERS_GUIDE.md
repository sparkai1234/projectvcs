# ğŸš€ DIVA Supabase Scrapers v2.0 - Enhanced Data Extraction

## ğŸ“‹ Overview

The updated DIVA scraping system now targets **Supabase** directly and includes **enhanced data extraction** with a focus on:

### ğŸ¯ **Key Enhancements:**
- **ëŒ€í‘œí€ë“œë§¤ë‹ˆì € (Fund Manager Representative)** extraction for Fund data
- **ëŒ€í‘œ (Company Representative)** extraction for VC company data  
- **Operating Amount accuracy** preservation (stored in ì–µì› as per vcs.go.kr)
- **Direct Supabase integration** (no more Airtable dependency)
- **Enhanced data quality tracking** and validation
- **Comprehensive field mapping** for both VC and Fund tables

---

## ğŸ—ï¸ **Architecture Overview**

### **Old System (Archived):**
```
vcs.go.kr â†’ Apify â†’ Airtable â†’ Manual Migration â†’ Supabase
```

### **New System (Current):**
```
vcs.go.kr â†’ Enhanced Scrapers â†’ Supabase (Direct)
```

---

## ğŸ“¦ **Installation & Setup**

### **1. Install Node.js Dependencies**
```bash
cd src/supabase
npm install
```

### **2. Verify Configuration**
The scrapers are pre-configured with your Supabase credentials. Check:
- **URL**: `https://udfgtccxbqmalgpqyxzz.supabase.co`
- **Service Role Key**: Already configured in scrapers

### **3. Verify Supabase Tables**
Ensure these tables exist:
- `vc_table` (for VC company data)
- `fund_table` (for fund data)

---

## ğŸš€ **Usage**

### **Option 1: Python Wrappers (Recommended)**

#### **Run Fund Scraper:**
```bash
# Scrape all fund pages with enhanced manager data
python run_supabase_fund_scraper.py

# Limit to 5 pages for testing
python run_supabase_fund_scraper.py --max-pages 5

# Start from page 10
python run_supabase_fund_scraper.py --start-page 10

# Disable detailed scraping (faster)
python run_supabase_fund_scraper.py --no-detailed-scraping
```

#### **Run VC Scraper:**
```bash
# Scrape all VC company pages
python run_supabase_vc_scraper.py

# Limit to 3 pages for testing
python run_supabase_vc_scraper.py --max-pages 3

# Quick scraping without detailed extraction
python run_supabase_vc_scraper.py --no-detailed-scraping
```

### **Option 2: Direct Node.js Execution**

#### **Fund Scraper:**
```bash
cd src/supabase
node supabase_fund_scraper.js
```

#### **VC Scraper:**
```bash
cd src/supabase
node supabase_vc_scraper.js
```

---

## ğŸ” **Enhanced Data Extraction**

### **Fund Data Enhancements:**

#### **ğŸ¦ Enhanced Fund Manager Extraction:**
The fund scraper now extracts `ëŒ€í‘œí€ë“œë§¤ë‹ˆì €` information from multiple sources:

```javascript
// Primary extraction sources
const fundManager = 
    item.reprsntNm ||          // Representative name field
    item.fundMngrNm ||         // Fund manager name field  
    item.operInstReprsntNm ||  // Operating institution representative
    item.operReprsntNm ||      // Operator representative
    item.mngrNm ||             // Manager name
    item.ceoNm ||              // CEO name
    item.reprsnt ||            // Representative
    item.fundReprsnt ||        // Fund representative
    null;
```

#### **ğŸ“Š Populated Fields:**
- `representative`: **ëŒ€í‘œí€ë“œë§¤ë‹ˆì €** name â­ **KEY FIELD**
- `fund_name`: Fund name in Korean
- `fund_size`: Size in ì› (converted from ì–µì›)
- `establishment_date`: Fund establishment date
- `expiry_date`: Fund expiry date
- `investment_detail`: Investment focus areas
- `company_id`: Linked VC company ID

### **VC Data Enhancements:**

#### **ğŸ¢ Enhanced Representative Extraction:**
The VC scraper extracts company representative information:

```javascript
// Representative extraction sources
const representative = 
    item.reprsntNm ||          // Representative name field
    item.operInstReprsntNm ||  // Operating institution representative
    item.ceoNm ||              // CEO name
    item.reprsnt ||            // Representative
    item.mngrNm ||             // Manager name
    null;
```

#### **ğŸ’° Operating Amount Accuracy:**
- Preserves original ì–µì› units from vcs.go.kr
- No unnecessary conversions
- Maintains data accuracy for AI analysis

#### **ğŸ“Š Populated Fields:**
- `representative`: **ëŒ€í‘œ** name â­ **KEY FIELD**
- `company_name`: Company name in Korean
- `operating_amount`: Operating amount in ì–µì›
- `location`: Company location
- `established_date`: Company establishment date
- `website_url`: Company website
- `contact_info`: Structured contact data

---

## ğŸ“ˆ **Data Quality Tracking**

### **Real-time Quality Metrics:**
Both scrapers provide real-time data quality feedback:

```
ğŸ“‹ Fund Manager Data: 156/200 records (78.0%) have manager info
ğŸ‘¤ Representative Data: 45/50 records (90.0%) have representative info
ğŸ’° Operating Amount Data: 48/50 records (96.0%) have operating amounts
```

### **Confidence Scoring:**
- **High Confidence**: Direct field extraction
- **Low Confidence**: Missing or inferred data

---

## ğŸ”„ **Integration with OpenAI Interface**

### **Enhanced Fund Display:**
The comprehensive OpenAI interface now shows fund manager information:

```markdown
=== ğŸ’¼ í€ë“œ í¬íŠ¸í´ë¦¬ì˜¤ ===
í€ë“œëª…: ë¯¸ë˜ì—ì…‹ í”„ë¼ì´ë¹— ì—ì¿¼í‹° ì œ3í˜¸
  ê·œëª¨: 2000 ì–µì›
  ì„¤ë¦½ì¼: 2023-03-15
  ğŸ‘¤ ëŒ€í‘œí€ë“œë§¤ë‹ˆì €: ê¹€ì² ìˆ˜
  íˆ¬ìë¶„ì•¼: ì¤‘ì†Œ/ë²¤ì²˜ì¼ë°˜
  ë§Œë£Œì¼: 2028-03-14
```

### **Query Examples:**
```python
# Query fund manager information
analyzer.ask_comprehensive_question("ë¯¸ë˜ì—ì…‹ë²¤ì²˜íˆ¬ìì˜ ëŒ€í‘œí€ë“œë§¤ë‹ˆì €ëŠ” ëˆ„êµ¬ì¸ê°€ìš”?")

# Query operating amounts with enhanced accuracy
analyzer.ask_comprehensive_question("ìŠ¤í†¤ë¸Œë¦¿ì§€ë²¤ì²˜ìŠ¤ì˜ ìš´ìš©ìì‚° ê·œëª¨ëŠ”?")
```

---

## âš™ï¸ **Configuration Options**

### **Scraper Configuration:**
Each scraper can be configured via environment variables or direct modification:

```javascript
const SCRAPER_CONFIG = {
    maxPages: null,              // null = all pages
    startPage: 1,                // Starting page
    batchSize: 20,               // Records per batch  
    delayBetweenRequests: 100,   // ms delay between requests
    delayBetweenBatches: 300,    // ms delay between batches
    enableDetailedScraping: true // Enhanced data extraction
};
```

### **Performance Tuning:**

#### **For Speed:**
```bash
# Disable detailed scraping for faster execution
python run_supabase_fund_scraper.py --no-detailed-scraping --max-pages 10
```

#### **For Maximum Data Quality:**
```bash
# Enable all enhancements (default)
python run_supabase_fund_scraper.py
```

---

## ğŸ“Š **Expected Results**

### **Fund Table Results:**
- **Total Records**: ~3,000-4,000 funds
- **Manager Data Coverage**: 70-80% with representative names
- **Financial Data**: 95%+ with fund sizes
- **Investment Focus**: 90%+ with investment details

### **VC Table Results:**
- **Total Records**: ~700-800 VC companies  
- **Representative Data**: 85-90% with representative names
- **Operating Amounts**: 95%+ with operating amounts in ì–µì›
- **Contact Info**: 80%+ with website URLs

---

## ğŸ”§ **Troubleshooting**

### **Common Issues:**

#### **"Node.js not found"**
```bash
# Install Node.js (version 16+)
# Windows: Download from nodejs.org
# Mac: brew install node
# Linux: sudo apt install nodejs npm
```

#### **"Supabase connection error"**
- Verify service role key in scraper files
- Check network connectivity
- Ensure Supabase project is active

#### **"Low data quality"**
- Check if enhanced scraping is enabled
- Verify vcs.go.kr website accessibility
- Review rate limiting settings

### **Performance Issues:**
```bash
# Reduce batch size for slower connections
# Edit SCRAPER_CONFIG.batchSize in scraper files

# Increase delays for rate limiting
# Edit SCRAPER_CONFIG.delayBetweenRequests
```

---

## ğŸ“ **File Structure**

```
ğŸ“‚ DIVA Intelligence System
â”œâ”€â”€ ğŸ“‚ archive/                     # Archived Airtable versions
â”‚   â”œâ”€â”€ airtable_fund_scraper.js   # Old fund scraper
â”‚   â””â”€â”€ airtable_vc_scraper.js     # Old VC scraper
â”œâ”€â”€ ğŸ“‚ src/supabase/               # New Supabase scrapers
â”‚   â”œâ”€â”€ package.json               # Node.js dependencies
â”‚   â”œâ”€â”€ supabase_fund_scraper.js   # Enhanced fund scraper
â”‚   â””â”€â”€ supabase_vc_scraper.js     # Enhanced VC scraper
â”œâ”€â”€ run_supabase_fund_scraper.py   # Python wrapper for funds
â”œâ”€â”€ run_supabase_vc_scraper.py     # Python wrapper for VCs
â””â”€â”€ comprehensive_vc_openai_interface.py # Updated AI interface
```

---

## ğŸ¯ **Next Steps**

### **1. Test the Scrapers:**
```bash
# Quick test with limited pages
python run_supabase_fund_scraper.py --max-pages 2
python run_supabase_vc_scraper.py --max-pages 2
```

### **2. Verify Data Quality:**
```bash
# Check fund manager data in Supabase
python -c "
from comprehensive_vc_openai_interface import ComprehensiveVCAnalyzer
analyzer = ComprehensiveVCAnalyzer()
analyzer.ask_comprehensive_question('ëŒ€í‘œí€ë“œë§¤ë‹ˆì € ì •ë³´ê°€ ìˆëŠ” í€ë“œë“¤ì„ ë³´ì—¬ì£¼ì„¸ìš”')
"
```

### **3. Full Production Run:**
```bash
# Run complete scraping
python run_supabase_fund_scraper.py
python run_supabase_vc_scraper.py
```

---

## âœ… **Success Criteria**

### **âœ… Fund Scraper Success:**
- [ ] Fund table populated with 3,000+ records
- [ ] 70%+ records have representative (ëŒ€í‘œí€ë“œë§¤ë‹ˆì €) data
- [ ] 95%+ records have fund size data
- [ ] Investment details properly extracted

### **âœ… VC Scraper Success:**
- [ ] VC table populated with 700+ records  
- [ ] 85%+ records have representative (ëŒ€í‘œ) data
- [ ] 95%+ records have operating amount data
- [ ] Contact information properly structured

### **âœ… Integration Success:**
- [ ] OpenAI interface displays fund manager names
- [ ] Representative information visible in queries
- [ ] Operating amounts accurate in ì–µì› units

---

## ğŸ‰ **Benefits of New System**

### **ğŸš€ Performance:**
- **Direct Supabase integration** (no migration needed)
- **Faster execution** with larger batch sizes
- **Real-time progress tracking**

### **ğŸ“Š Data Quality:**
- **Enhanced field extraction** for key personnel data
- **Multiple fallback sources** for representative information
- **Comprehensive validation** and quality scoring

### **ğŸ”§ Maintainability:**
- **No Airtable dependency** (cost savings)
- **Modular architecture** with Python wrappers
- **Easy configuration** via command-line arguments

### **ğŸ¯ Accuracy:**
- **ëŒ€í‘œí€ë“œë§¤ë‹ˆì € data** now properly captured and displayed
- **Operating amounts** preserved in original ì–µì› units
- **Investment focus** areas properly categorized

**Ready to transform your VC data pipeline with enhanced accuracy! ğŸš€** 