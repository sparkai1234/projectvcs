# ğŸš€ **APIFY SETUP GUIDE** - Deploy Your VCS Scraper

## ğŸ¯ **QUICK DEPLOYMENT (10 MINUTES)**

### **Step 1: Prepare Actor Files**
```bash
# 1. Zip the apify/vcs-scraper directory
cd apify/vcs-scraper
zip -r korean-vcs-scraper.zip . 

# Files included:
# â”œâ”€â”€ main.js (main scraper logic)
# â”œâ”€â”€ package.json (dependencies)
# â””â”€â”€ INPUT_SCHEMA.json (UI form configuration)
```

### **Step 2: Deploy to Apify Console**

1. **Go to [Apify Console](https://console.apify.com)**
2. **Click "Create New" â†’ "Actor"**
3. **Upload your zip file** or copy-paste the code
4. **Name**: `korean-vc-vcs-scraper`
5. **Click "Build & Run"**

### **Step 3: Configure Weekly Schedule (UI-Based)**

**ğŸ›ï¸ IN APIFY CONSOLE (NO CODE NEEDED):**

1. **Click "Schedules" tab**
2. **Click "Create Schedule"**
3. **Fill out the form:**
   ```
   Name: VCS Weekly Update
   Cron Expression: 0 6 * * 0  (Sundays 6 AM)
   Timezone: Asia/Seoul
   ```
4. **Click "Save"**

**That's it! No YAML editing, no code deployment!**

---

## ğŸ¯ **UI-BASED PARAMETER MANAGEMENT**

### **INSTEAD OF CODE EDITING:**

**âŒ GitHub Actions Way:**
```yaml
# Edit this every time you want to change settings:
env:
  MAX_PAGES: 100
  UPDATE_MODE: incremental
  DATA_SOURCE: both
```

**âœ… Apify Console Way:**
1. **Go to Actor â†’ Input tab**
2. **Use dropdown menus:**
   - ğŸ“Š Update Mode: [Full Scrape â–¼]
   - ğŸ¯ Data Source: [Both â–¼] 
   - ğŸ“„ Max Pages: [100]
   - ğŸ“§ Notifications: [âœ“]
3. **Click "Save & Start"**

---

## ğŸ“… **OPTIMAL WEEKLY SCHEDULE**

### **RECOMMENDED APIFY SCHEDULES:**

#### **VCS Scraper (Primary)**
```
Schedule Name: VCS Weekly Data Update
Cron: 0 6 * * 0 (Sundays 6:00 AM KST)
Actor: korean-vc-vcs-scraper
Input: {
  "updateMode": "incremental",
  "dataSource": "both", 
  "maxPages": 100,
  "notifyOnCompletion": true
}
```

#### **DIVA Scraper (Coming Next Week)**
```
Schedule Name: DIVA Weekly Financial Data
Cron: 0 8 * * 3 (Wednesdays 8:00 AM KST)
Actor: korean-vc-diva-scraper
Input: {
  "dataTypes": ["investments", "violations", "reports"],
  "notifyOnCompletion": true
}
```

#### **Government Data (Coming Week 3)**
```
Schedule Name: Government Weekly Data
Cron: 0 7 * * 5 (Fridays 7:00 AM KST)
Actor: korean-vc-government-scraper  
Input: {
  "sources": ["kgrowth", "kdb", "kvic"],
  "notifyOnCompletion": true
}
```

---

## ğŸ›ï¸ **APIFY CONSOLE ADVANTAGES**

### **ğŸŒŸ UI FEATURES YOU'LL LOVE:**

#### **ğŸ“Š Visual Dashboard:**
- **Real-time run monitoring** with progress bars
- **Visual charts** of data scraped over time
- **Performance metrics** (duration, success rate)
- **Data preview** with searchable interface

#### **âš™ï¸ Easy Configuration:**
- **Point-and-click scheduling** (no cron expressions to memorize)
- **Dropdown parameter selection** (no typing required)
- **Instant parameter changes** (no code deployment)
- **One-click manual triggers** (test anytime)

#### **ğŸ“§ Professional Notifications:**
- **Email alerts** on completion/failure
- **Slack integration** for team notifications
- **Webhook support** for custom integrations
- **SMS alerts** for critical failures

#### **ğŸ’¾ Data Management:**
- **Organized datasets** with automatic storage
- **API access** to all your scraped data
- **Multiple export formats** (JSON, CSV, Excel)
- **Data retention policies** (automatic cleanup)

---

## ğŸ”§ **CONFIGURATION EXAMPLES**

### **FOR TESTING (FIRST TIME):**
```json
{
  "updateMode": "incremental",
  "dataSource": "investors", 
  "maxPages": 5,
  "notifyOnCompletion": true,
  "exportToSupabase": false
}
```

### **FOR PRODUCTION (WEEKLY RUNS):**
```json
{
  "updateMode": "incremental",
  "dataSource": "both",
  "maxPages": 100, 
  "notifyOnCompletion": true,
  "exportToSupabase": true,
  "supabaseUrl": "https://your-project.supabase.co",
  "supabaseKey": "your-service-role-key"
}
```

### **FOR MONTHLY FULL REFRESH:**
```json
{
  "updateMode": "full",
  "dataSource": "both",
  "maxPages": 500,
  "notifyOnCompletion": true,
  "exportToSupabase": true
}
```

---

## ğŸ“Š **MONITORING & ALERTS**

### **APIFY WILL AUTOMATICALLY:**
- **ğŸ“ˆ Track performance** (duration, records scraped)
- **ğŸš¨ Send alerts** on failures or anomalies
- **ğŸ“Š Generate reports** on data quality
- **ğŸ”„ Retry failures** with exponential backoff
- **ğŸ“± Mobile notifications** via Apify mobile app

### **DASHBOARD FEATURES:**
```
ğŸ“Š Real-time Metrics:
â”œâ”€â”€ âœ… Successful runs: 47/50 (94%)
â”œâ”€â”€ â±ï¸ Average duration: 3.2 minutes  
â”œâ”€â”€ ğŸ“ˆ Records per run: ~4,400
â”œâ”€â”€ ğŸ¯ Data quality: 99.8%
â””â”€â”€ ğŸ“… Next run: Sunday 6:00 AM KST
```

---

## ğŸ¯ **NEXT STEPS:**

### **TODAY:**
1. **ğŸ“¤ Deploy VCS actor** to Apify (10 minutes)
2. **âš™ï¸ Set weekly schedule** via UI (2 minutes)
3. **ğŸ§ª Test with small dataset** (5 minutes)

### **THIS WEEKEND:**
1. **ğŸ”„ First automated Sunday run** 
2. **ğŸ“Š Monitor dashboard** for success
3. **ğŸ“§ Verify notifications** work

### **NEXT WEEK:**
1. **ğŸ“ˆ Add DIVA scraper** for financial data
2. **ğŸ›ï¸ Configure Wednesday schedule**
3. **ğŸ”— Integrate with existing workflows**

**Your Korean VC Intelligence Platform will run itself while you focus on analysis! ğŸ‡°ğŸ‡·âš¡** 