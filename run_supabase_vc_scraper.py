#!/usr/bin/env python3
"""
Python wrapper for running the Supabase VC Scraper
Executes the Node.js scraper with proper configuration
"""

import subprocess
import sys
import os
import json
from datetime import datetime

def run_vc_scraper(max_pages=None, start_page=1, enable_detailed_scraping=True):
    """Run the Supabase VC scraper with specified parameters"""
    
    print("ğŸ¢ DIVA VC Scraper for Supabase")
    print("=" * 60)
    print(f"ğŸ“ Enhanced with ëŒ€í‘œ (Representative) & Operating Amount Data Extraction")
    print(f"ğŸ“… Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # Configuration
    config = {
        'maxPages': max_pages,
        'startPage': start_page,
        'enableDetailedScraping': enable_detailed_scraping,
        'batchSize': 25,
        'delayBetweenRequests': 100,
        'delayBetweenBatches': 300
    }
    
    print(f"âš™ï¸ Configuration:")
    print(f"   â€¢ Max Pages: {max_pages or 'ALL'}")
    print(f"   â€¢ Start Page: {start_page}")
    print(f"   â€¢ Enhanced Scraping: {enable_detailed_scraping}")
    print(f"   â€¢ Target: Supabase vc_table")
    print()
    
    # Check if Node.js is available
    try:
        subprocess.run(['node', '--version'], check=True, capture_output=True)
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("âŒ Node.js is required but not found. Please install Node.js first.")
        return False
    
    # Check if the scraper file exists
    scraper_path = 'src/supabase/supabase_vc_scraper.js'
    if not os.path.exists(scraper_path):
        print(f"âŒ Scraper file not found: {scraper_path}")
        return False
    
    try:
        print("ğŸš€ Starting VC scraper...")
        
        # Set environment variables for configuration
        env = os.environ.copy()
        env['SCRAPER_CONFIG'] = json.dumps(config)
        
        # Run the Node.js scraper
        process = subprocess.run(
            ['node', scraper_path],
            env=env,
            capture_output=False,  # Show real-time output
            text=True
        )
        
        if process.returncode == 0:
            print("\nâœ… VC scraper completed successfully!")
            print("ğŸ“Š Check Supabase vc_table for new records with enhanced representative data")
            return True
        else:
            print(f"\nâŒ VC scraper failed with exit code: {process.returncode}")
            return False
            
    except Exception as e:
        print(f"âŒ Error running VC scraper: {e}")
        return False

def main():
    """Main execution function"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Run Supabase VC Scraper')
    parser.add_argument('--max-pages', type=int, help='Maximum pages to scrape (default: all)')
    parser.add_argument('--start-page', type=int, default=1, help='Starting page number')
    parser.add_argument('--no-detailed-scraping', action='store_true', help='Disable detailed representative scraping')
    
    args = parser.parse_args()
    
    # Run the scraper
    success = run_vc_scraper(
        max_pages=args.max_pages,
        start_page=args.start_page,
        enable_detailed_scraping=not args.no_detailed_scraping
    )
    
    if success:
        print("\nğŸ‰ VC data successfully scraped to Supabase!")
        print("ğŸ’¡ You can now use comprehensive_vc_openai_interface.py to query representative information")
    else:
        print("\nâŒ VC scraping failed. Check the error messages above.")
        sys.exit(1)

if __name__ == "__main__":
    main() 